geom_vline( xintercept = LDA_decision_boundary, linetype = "solid" ) +
geom_vline( xintercept = bayes_decision_boundary, linetype = "dashed" )
imdb <- read.csv("data/imdb_rating.csv")
head(imdb)
summary( imdb[7:20] )
str(imdb)
### change data type and remove NA's from the data
imdb$genres <- as.character(imdb$genres)
imdb <- na.omit(imdb)
### Now we want to extract the first movie genre from the column and find the frequency of the genre in the data set
genre <- sapply( imdb$genres, strsplit,"[|]", USE.NAMES = FALSE )
get_one_genre <- function(entry) for(i in entry) return(i[[1]])
imdb$genres <- unlist(lapply(genre, get_one_genre))
table_genre <- table(imdb$genres)
table_genre
### Here we are selecting observations greather than 50 and less than 400 alse
### creating a vector containing the name of the classes that are interested
table_genre_400 <- table_genre[ table_genre > 50 & table_genre < 400 ]
y_classes <- names(table_genre_400[ c(1,2,4) ])
y_classes
### To create ROC plot for two classes
#y_classes <- y_classes[c(1,3)]
movies <- imdb[ imdb$genres %in% y_classes, ]
movies <- movies[ movies$year > 2006, ]
### Here we are only selecting genre and other numeric values that we are going to use to create the model
head(movies)
movies <- movies[ c(2,7:18,20) ]
### First lets selesct two classes so we can later create an ROC plot
y_classes_mlr <- y_classes[ c(1,3) ]
### Select only movies mad ein the last 10 years within the selected classes
movies_mlr <- imdb[ imdb$genres %in% y_classes_mlr,]
movies_mlr <- movies_mlr[ movies_mlr$year > 2006, ]
### Disregard non-numeric variables and some correlated variables
movies_mlr <- movies_mlr[c(2,7:18,20)]
### Create a mlr task object using the movies dataset and gender as a target
movies_mlr.task <- makeClassifTask(data = movies_mlr, target = "genres")
### Now we can create the Training (~65%) and Testing (~35%) sets based on the number of samples
n = getTaskSize(movies_mlr.task)
train_mlr.set = sample( n, size = round(2/3 * n) )
test_mlr.set = setdiff( seq_len(n), train_mlr.set )
### Here we are creating a random sample of size n=100 from the dataset
### the sample function return the index of the selected rows
idx_smp <- sample(seq_len(nrow(movies)), size = 100)
### Now we extract select that datsa using the index of the rows and take another sample
### But this time is to create the Training and Testing sets
movies <- movies[idx_smp,]
smp_size <- floor(0.75 * nrow(movies))
train_ind <- sample(seq_len(nrow(movies)), size = smp_size)
### TRAINING
train_data <- movies[ train_ind, ]
### TESTING
test_data <- movies[ -train_ind, ]
### Labels from the testing set
y_test <- as.factor(test_data['genres']$genres)
test_data['genres'] <- NULL
selected_columns = c('director_fb_likes',
'total_cast_likes',
'fb_likes',
'users_votes',
'score',
'gross')
#plot(train)
plot( train_data[ selected_columns ] )
### Uncomment to use all the columns in the dataset
#zscores <- apply(train, 1, function(x) (x - mean(x)) / sd(x))
zscores <- apply( train_data[selected_columns], 1, function(x) (x - mean(x)) / sd(x))
zscores <- data.frame( t(zscores) )
corr <- cor(zscores)
corrplot(corr)
### Here we are making a object of type makeLearner using the LDA classifier
lrn = makeLearner("classif.lda", predict.type = "prob")
### Now using the train function in mlr we can train our model using the training set
mod = train(lrn, task = movies_mlr.task, subset = train_mlr.set)
### After trining the model we test it on the testing data
pred = predict(mod, task = movies_mlr.task, subset = test_mlr.set)
### Measure performance of prediction
performance(pred, measures = list(mmce, acc))
df = generateThreshVsPerfData(pred, measures = list(fpr, tpr) )
head(df)
plotROCCurves(df)
plotThreshVsPerf(df)
### Uncomment to create a model containing only selected columns
#lda.fit = lda( genres ~ ., data = train_data[ c('genres', selected_columns) ])
lda.fit = lda(genres ~ ., data=train_data)
lda.fit
plot(lda.fit)
lda.pred = predict( lda.fit, test_data )
names(lda.pred)
lda.class = lda.pred$class
table(lda.class, y_test)
mean(lda.class == y_test)
### Here we are only selecting genre and other numeric values that we are going to use to create the model
movies <- imdb[ imdb$genres %in% y_classes, ]
movies <- movies[ movies$year > 1996, ]
movies <- movies[ c(2,7:18,20) ]
### Now we extract select that datsa using the index of the rows and take another sample
### But this time is to create the Training and Testing sets
idx_smp <- sample(seq_len(nrow(movies)), size = 500)
movies <- movies[idx_smp,]
smp_size <- floor(0.75 * nrow(movies))
train_ind <- sample(seq_len(nrow(movies)), size = smp_size)
### TRAINING
train_data <- movies[ train_ind, ]
### TESTING
test_data <- movies[ -train_ind, ]
### Labels from the testing set
y_test <- as.factor(test_data['genres']$genres)
test_data['genres'] <- NULL
qda.fit = qda(genres ~ ., data = train_data)
qda.fit
qda.pred = predict(qda.fit, test_data)
qda.class = qda.pred$class
table(qda.class, y_test)
mean(qda.class == y_test)
#### load and install packages if necessary
### https://mlr-org.github.io/
if(!require("mlr")) install.packages("mlr")
### http://www.stats.ox.ac.uk/pub/MASS4/
if(!require("MASS")) install.packages("MASS")
### http://ggplot2.org/
if(!require("ggplot2")) install.packages("ggplot2")
### https://github.com/taiyun/corrplot
if(!require("corrplot")) install.packages("corrplot")
#### set seed and turn off scientific notation to see small/large numbers
set.seed(1234)
options(scipen = 9999)
#### load and install packages if necessary
### https://mlr-org.github.io/
if(!require("mlr")) install.packages("mlr")
### http://www.stats.ox.ac.uk/pub/MASS4/
if(!require("MASS")) install.packages("MASS")
### http://ggplot2.org/
if(!require("ggplot2")) install.packages("ggplot2")
### https://github.com/taiyun/corrplot
if(!require("corrplot")) install.packages("corrplot")
#### set seed and turn off scientific notation to see small/large numbers
set.seed(1234)
options(scipen = 9999)
mean_a <- 1.5
mean_b <- -1.5
bayes_decision_boundary <- (mean_a + mean_b)/2
p <- ggplot( data.frame(x=c(-4,4)), aes(x)) +
stat_function( fun = dnorm, args = list(mean = mean_a, sd = 1), col='red' ) +
stat_function( fun = dnorm, args = list(mean = mean_b, sd = 1), col='blue' )
p + geom_vline(xintercept = bayes_decision_boundary, linetype="dashed")
x <- seq(-4, 4, length = 500)
df <- data.frame(cond = rep(letters[1:2], each = 500),
values = c( rnorm(x,mean = mean_a, sd = 1), rnorm(x,mean = mean_b, sd = 1)))
head(df, n=5)
sample_a <- data.frame("values"= sample(df$values[df$cond=="a"], 100), "cond" = "a")
sample_b <- data.frame("values"= sample(df$values[df$cond=="b"], 100), "cond" = "b")
mean_sample_a <- mean( sample_a$values )
mean_sample_b <- mean( sample_b$values )
hist_a <- hist( sample_a$values, plot = FALSE )
hist_b <- hist( sample_b$values, plot = FALSE )
sigma_a <- weighted.mean( hist_a$density, hist_a$counts )
sigma_b <- weighted.mean( hist_b$density, hist_b$counts )
prob_a <- 30/100
prob_b <- 30/100
LDA_decision_boundary <- (mean_sample_a + mean_sample_b)/2
ggplot(df, aes(x = values, fill = cond)) +
geom_histogram( binwidth = 0.4, alpha = 0.5, position = "identity" ) +
geom_vline( xintercept = LDA_decision_boundary, linetype = "solid" ) +
geom_vline( xintercept = bayes_decision_boundary, linetype = "dashed" )
imdb <- read.csv("data/imdb_rating.csv")
head(imdb)
summary( imdb[7:20] )
str(imdb)
### change data type and remove NA's from the data
imdb$genres <- as.character(imdb$genres)
imdb <- na.omit(imdb)
### Now we want to extract the first movie genre from the column and find the frequency of the genre in the data set
genre <- sapply( imdb$genres, strsplit,"[|]", USE.NAMES = FALSE )
get_one_genre <- function(entry) for(i in entry) return(i[[1]])
imdb$genres <- unlist(lapply(genre, get_one_genre))
table_genre <- table(imdb$genres)
table_genre
### Here we are selecting observations greather than 50 and less than 400 alse
### creating a vector containing the name of the classes that are interested
table_genre_400 <- table_genre[ table_genre > 50 & table_genre < 400 ]
y_classes <- names(table_genre_400[ c(1,2,4) ])
y_classes
### To create ROC plot for two classes
#y_classes <- y_classes[c(1,3)]
movies <- imdb[ imdb$genres %in% y_classes, ]
movies <- movies[ movies$year > 2006, ]
### Here we are only selecting genre and other numeric values that we are going to use to create the model
head(movies)
movies <- movies[ c(2,7:18,20) ]
### First lets selesct two classes so we can later create an ROC plot
y_classes_mlr <- y_classes[ c(1,3) ]
### Select only movies mad ein the last 10 years within the selected classes
movies_mlr <- imdb[ imdb$genres %in% y_classes_mlr,]
movies_mlr <- movies_mlr[ movies_mlr$year > 2006, ]
### Disregard non-numeric variables and some correlated variables
movies_mlr <- movies_mlr[c(2,7:18,20)]
### Create a mlr task object using the movies dataset and gender as a target
movies_mlr.task <- makeClassifTask(data = movies_mlr, target = "genres")
### Now we can create the Training (~65%) and Testing (~35%) sets based on the number of samples
n = getTaskSize(movies_mlr.task)
train_mlr.set = sample( n, size = round(2/3 * n) )
test_mlr.set = setdiff( seq_len(n), train_mlr.set )
### Here we are creating a random sample of size n=100 from the dataset
### the sample function return the index of the selected rows
idx_smp <- sample(seq_len(nrow(movies)), size = 100)
### Now we extract select that datsa using the index of the rows and take another sample
### But this time is to create the Training and Testing sets
movies <- movies[idx_smp,]
smp_size <- floor(0.75 * nrow(movies))
train_ind <- sample(seq_len(nrow(movies)), size = smp_size)
### TRAINING
train_data <- movies[ train_ind, ]
### TESTING
test_data <- movies[ -train_ind, ]
### Labels from the testing set
y_test <- as.factor(test_data['genres']$genres)
test_data['genres'] <- NULL
selected_columns = c('director_fb_likes',
'total_cast_likes',
'fb_likes',
'users_votes',
'score',
'gross')
#plot(train)
plot( train_data[ selected_columns ] )
### Uncomment to use all the columns in the dataset
#zscores <- apply(train, 1, function(x) (x - mean(x)) / sd(x))
zscores <- apply( train_data[selected_columns], 1, function(x) (x - mean(x)) / sd(x))
zscores <- data.frame( t(zscores) )
corr <- cor(zscores)
corrplot(corr)
### Here we are making a object of type makeLearner using the LDA classifier
lrn = makeLearner("classif.lda", predict.type = "prob")
### Now using the train function in mlr we can train our model using the training set
mod = train(lrn, task = movies_mlr.task, subset = train_mlr.set)
### After trining the model we test it on the testing data
pred = predict(mod, task = movies_mlr.task, subset = test_mlr.set)
### Measure performance of prediction
performance(pred, measures = list(mmce, acc))
df = generateThreshVsPerfData(pred, measures = list(fpr, tpr) )
head(df)
plotROCCurves(df)
plotThreshVsPerf(df)
### Uncomment to create a model containing only selected columns
#lda.fit = lda( genres ~ ., data = train_data[ c('genres', selected_columns) ])
lda.fit = lda(genres ~ ., data=train_data)
lda.fit
plot(lda.fit)
lda.pred = predict( lda.fit, test_data )
names(lda.pred)
lda.class = lda.pred$class
table(lda.class, y_test)
mean(lda.class == y_test)
### Here we are only selecting genre and other numeric values that we are going to use to create the model
movies <- imdb[ imdb$genres %in% y_classes, ]
movies <- movies[ movies$year > 1996, ]
movies <- movies[ c(2,7:18,20) ]
### Now we extract select that datsa using the index of the rows and take another sample
### But this time is to create the Training and Testing sets
idx_smp <- sample(seq_len(nrow(movies)), size = 500)
movies <- movies[idx_smp,]
smp_size <- floor(0.75 * nrow(movies))
train_ind <- sample(seq_len(nrow(movies)), size = smp_size)
### TRAINING
train_data <- movies[ train_ind, ]
### TESTING
test_data <- movies[ -train_ind, ]
### Labels from the testing set
y_test <- as.factor(test_data['genres']$genres)
test_data['genres'] <- NULL
qda.fit = qda(genres ~ ., data = train_data)
qda.fit
qda.pred = predict(qda.fit, test_data)
qda.class = qda.pred$class
table(qda.class, y_test)
mean(qda.class == y_test)
#### load and install packages if necessary
### https://mlr-org.github.io/
if(!require("mlr",quietly = TRUE)) install.packages("mlr")
### http://www.stats.ox.ac.uk/pub/MASS4/
if(!require("MASS",quietly = TRUE)) install.packages("MASS")
### http://ggplot2.org/
if(!require("ggplot2",quietly = TRUE)) install.packages("ggplot2")
### https://github.com/taiyun/corrplot
if(!require("corrplot",quietly = TRUE)) install.packages("corrplot")
#### set seed and turn off scientific notation to see small/large numbers
set.seed(1234)
options(scipen = 9999)
mean_a <- 1.5
mean_b <- -1.5
bayes_decision_boundary <- (mean_a + mean_b)/2
p <- ggplot( data.frame(x=c(-4,4)), aes(x)) +
stat_function( fun = dnorm, args = list(mean = mean_a, sd = 1), col='red' ) +
stat_function( fun = dnorm, args = list(mean = mean_b, sd = 1), col='blue' )
p + geom_vline(xintercept = bayes_decision_boundary, linetype="dashed")
x <- seq(-4, 4, length = 500)
df <- data.frame(cond = rep(letters[1:2], each = 500),
values = c( rnorm(x,mean = mean_a, sd = 1), rnorm(x,mean = mean_b, sd = 1)))
head(df, n=5)
sample_a <- data.frame("values"= sample(df$values[df$cond=="a"], 100), "cond" = "a")
sample_b <- data.frame("values"= sample(df$values[df$cond=="b"], 100), "cond" = "b")
mean_sample_a <- mean( sample_a$values )
mean_sample_b <- mean( sample_b$values )
hist_a <- hist( sample_a$values, plot = FALSE )
hist_b <- hist( sample_b$values, plot = FALSE )
sigma_a <- weighted.mean( hist_a$density, hist_a$counts )
sigma_b <- weighted.mean( hist_b$density, hist_b$counts )
prob_a <- 30/100
prob_b <- 30/100
LDA_decision_boundary <- (mean_sample_a + mean_sample_b)/2
ggplot(df, aes(x = values, fill = cond)) +
geom_histogram( binwidth = 0.4, alpha = 0.5, position = "identity" ) +
geom_vline( xintercept = LDA_decision_boundary, linetype = "solid" ) +
geom_vline( xintercept = bayes_decision_boundary, linetype = "dashed" )
imdb <- read.csv("data/imdb_rating.csv")
head(imdb)
summary( imdb[7:20] )
str(imdb)
### change data type and remove NA's from the data
imdb$genres <- as.character(imdb$genres)
imdb <- na.omit(imdb)
### Now we want to extract the first movie genre from the column and find the frequency of the genre in the data set
genre <- sapply( imdb$genres, strsplit,"[|]", USE.NAMES = FALSE )
get_one_genre <- function(entry) for(i in entry) return(i[[1]])
imdb$genres <- unlist(lapply(genre, get_one_genre))
table_genre <- table(imdb$genres)
table_genre
### Here we are selecting observations greather than 50 and less than 400 alse
### creating a vector containing the name of the classes that are interested
table_genre_400 <- table_genre[ table_genre > 50 & table_genre < 400 ]
y_classes <- names(table_genre_400[ c(1,2,4) ])
y_classes
### To create ROC plot for two classes
#y_classes <- y_classes[c(1,3)]
movies <- imdb[ imdb$genres %in% y_classes, ]
movies <- movies[ movies$year > 2006, ]
### Here we are only selecting genre and other numeric values that we are going to use to create the model
head(movies)
movies <- movies[ c(2,7:18,20) ]
### First lets selesct two classes so we can later create an ROC plot
y_classes_mlr <- y_classes[ c(1,3) ]
### Select only movies mad ein the last 10 years within the selected classes
movies_mlr <- imdb[ imdb$genres %in% y_classes_mlr,]
movies_mlr <- movies_mlr[ movies_mlr$year > 2006, ]
### Disregard non-numeric variables and some correlated variables
movies_mlr <- movies_mlr[c(2,7:18,20)]
### Create a mlr task object using the movies dataset and gender as a target
movies_mlr.task <- makeClassifTask(data = movies_mlr, target = "genres")
### Now we can create the Training (~65%) and Testing (~35%) sets based on the number of samples
n = getTaskSize(movies_mlr.task)
train_mlr.set = sample( n, size = round(2/3 * n) )
test_mlr.set = setdiff( seq_len(n), train_mlr.set )
### Here we are creating a random sample of size n=100 from the dataset
### the sample function return the index of the selected rows
idx_smp <- sample(seq_len(nrow(movies)), size = 100)
### Now we extract select that datsa using the index of the rows and take another sample
### But this time is to create the Training and Testing sets
movies <- movies[idx_smp,]
smp_size <- floor(0.75 * nrow(movies))
train_ind <- sample(seq_len(nrow(movies)), size = smp_size)
### TRAINING
train_data <- movies[ train_ind, ]
### TESTING
test_data <- movies[ -train_ind, ]
### Labels from the testing set
y_test <- as.factor(test_data['genres']$genres)
test_data['genres'] <- NULL
selected_columns = c('director_fb_likes',
'total_cast_likes',
'fb_likes',
'users_votes',
'score',
'gross')
#plot(train)
plot( train_data[ selected_columns ] )
### Uncomment to use all the columns in the dataset
#zscores <- apply(train, 1, function(x) (x - mean(x)) / sd(x))
zscores <- apply( train_data[selected_columns], 1, function(x) (x - mean(x)) / sd(x))
zscores <- data.frame( t(zscores) )
corr <- cor(zscores)
corrplot(corr)
### Here we are making a object of type makeLearner using the LDA classifier
lrn = makeLearner("classif.lda", predict.type = "prob")
### Now using the train function in mlr we can train our model using the training set
mod = train(lrn, task = movies_mlr.task, subset = train_mlr.set)
### After trining the model we test it on the testing data
pred = predict(mod, task = movies_mlr.task, subset = test_mlr.set)
### Measure performance of prediction
performance(pred, measures = list(mmce, acc))
df = generateThreshVsPerfData(pred, measures = list(fpr, tpr) )
head(df)
plotROCCurves(df)
plotThreshVsPerf(df)
### Uncomment to create a model containing only selected columns
#lda.fit = lda( genres ~ ., data = train_data[ c('genres', selected_columns) ])
lda.fit = lda(genres ~ ., data=train_data)
lda.fit
plot(lda.fit)
lda.pred = predict( lda.fit, test_data )
names(lda.pred)
lda.class = lda.pred$class
table(lda.class, y_test)
mean(lda.class == y_test)
### Here we are only selecting genre and other numeric values that we are going to use to create the model
movies <- imdb[ imdb$genres %in% y_classes, ]
movies <- movies[ movies$year > 1996, ]
movies <- movies[ c(2,7:18,20) ]
### Now we extract select that datsa using the index of the rows and take another sample
### But this time is to create the Training and Testing sets
idx_smp <- sample(seq_len(nrow(movies)), size = 500)
movies <- movies[idx_smp,]
smp_size <- floor(0.75 * nrow(movies))
train_ind <- sample(seq_len(nrow(movies)), size = smp_size)
### TRAINING
train_data <- movies[ train_ind, ]
### TESTING
test_data <- movies[ -train_ind, ]
### Labels from the testing set
y_test <- as.factor(test_data['genres']$genres)
test_data['genres'] <- NULL
qda.fit = qda(genres ~ ., data = train_data)
qda.fit
qda.pred = predict(qda.fit, test_data)
qda.class = qda.pred$class
table(qda.class, y_test)
mean(qda.class == y_test)
library(readr)
dataset <- read_csv(NULL)
View(dataset)
library(readr)
emba <- read_csv("~/Downloads/emba.csv")
View(emba)
hist(emba$total_normal)
summar(emba[2:7])
summary(emba[2:7])
hist(emba$total_normal,breaks = 4)
hist(emba$total_normal,breaks = 6)
hist(emba$total_normal,breaks = 4)
hist(emba$total_normal,breaks = 5)
hist(emba$total_normal,breaks = 6)
hist(emba$total_normal,breaks = 5)
hist(emba$total_normal)
hist(emba$total_normal,breaks = 6)
hist(emba$total_normal,breaks = 5)
seq(1,20000,2)
seq(2,20000,2)
seq(1,64000,16)
seq(0,64000,16)
seq(8,64000,16)
geomSeries <- function(base, max) {
base^(0:floor(log(max, base)))
}
geomSeries(8,64000)
geomSeries(8,30000000)
x = geomSeries(8,30000000)
gnu <- read.csv("gnu30.csv")
intel <- read.csv("intel30.csv")
names = c("size","fill","copy","axpy","dot","uncertainty")
colnames(gnu) = names
colnames(intel) = names
setwd("~/space/LOYOLA/GRAD/F17/COMP464/high-performance/projects/01-stream")
library(ggplot2)
gnu <- read.csv("gnu30.csv")
intel <- read.csv("intel30.csv")
names = c("size","fill","copy","axpy","dot","uncertainty")
colnames(gnu) = names
colnames(intel) = names
ggplot(intel[1:5], aes(x) )+
geom_line(aes(y=fill), colour="red") +
geom_line(aes(y=copy), colour="green") +
geom_line(aes(y=axpy), colour="blue") +
geom_line(aes(y=dot), colour="black")
intel[1:5]
geomSeries(4,30000000)
geomSeries(2,30000000)
geomSeries(2,50000000)
geomSeries(2,40000000)
x = geomSeries(2,40000000)
x = geomSeries(2,60000000)
x = geomSeries(2,90000000)
x
geomSeries(2,40000000)
x = geomSeries(2,40000000)
ggplot(intel[1:26,][1:5], aes(x) )+
geom_line(aes(y=fill), colour="red") +
geom_line(aes(y=copy), colour="green") +
geom_line(aes(y=axpy), colour="blue") +
geom_line(aes(y=dot), colour="black")
x = geomSeries(8,40000000)
x
ggplot(intel[1:9,][1:5], aes(x) )+
geom_line(aes(y=fill), colour="red") +
geom_line(aes(y=copy), colour="green") +
geom_line(aes(y=axpy), colour="blue") +
geom_line(aes(y=dot), colour="black")
options(scipen = 9999)
ggplot(intel[1:9,][1:5], aes(x) )+
geom_line(aes(y=fill), colour="red") +
geom_line(aes(y=copy), colour="green") +
geom_line(aes(y=axpy), colour="blue") +
geom_line(aes(y=dot), colour="black")
x = geomSeries(8,30000000)
ggplot(intel[1:9,][1:5], aes(x) )+
geom_line(aes(y=fill), colour="red") +
geom_line(aes(y=copy), colour="green") +
geom_line(aes(y=axpy), colour="blue") +
geom_line(aes(y=dot), colour="black")
log
log()
log(intel$fill,10)
log(intel$fill,2)
log(intel$fill,10)
